{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline output:\n",
    "    Precision = 0.243110\n",
    "    Recall = 0.544379\n",
    "    AER = 0.681684"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold -t 0.5 output:\n",
    "    Precision = 0.834483\n",
    "    Recall = 0.340237\n",
    "    AER = 0.511387"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Guess output:\n",
    "    Precision = 0.574202\n",
    "    Recall = 0.730769\n",
    "    AER = 0.375826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "paths = {\"full_a\": \"hansards.a\", \n",
    "        \"full_e\": \"hansards.e\", \n",
    "        \"full_f\": \"hansards.f\",\n",
    "        \"dev_a\": \"dev.a\",\n",
    "        \"dev_e\": \"dev.e\",\n",
    "        \"dev_f\": \"dev.f\"}\n",
    "\n",
    "# Proof of concept with shortened (first 37) list\n",
    "with open(paths[\"dev_a\"], \"r\", encoding=\"utf-8\") as dev_a:\n",
    "    dev_a_sentences = dev_a.readlines()\n",
    "with open(paths[\"dev_e\"], \"r\", encoding=\"utf-8\") as dev_e:\n",
    "    dev_e_sentences = dev_e.readlines()\n",
    "    for i, line in enumerate(dev_e_sentences):\n",
    "        dev_e_sentences[i] = line.split()\n",
    "with open(paths[\"dev_f\"], \"r\", encoding=\"utf-8\") as dev_f:\n",
    "    dev_f_sentences = dev_f.readlines()\n",
    "    for i, line in enumerate(dev_f_sentences):\n",
    "        dev_f_sentences[i] = line.split()\n",
    "\n",
    "with open(paths[\"full_e\"], \"r\", encoding=\"utf-8\") as full_e:\n",
    "    full_e_sentences = full_e.readlines()\n",
    "    for i, line in enumerate(full_e_sentences):\n",
    "        full_e_sentences[i] = line.split()\n",
    "with open(paths[\"full_f\"], \"r\", encoding=\"utf-8\") as full_f:\n",
    "    full_f_sentences = full_f.readlines()\n",
    "    for i, line in enumerate(full_f_sentences):\n",
    "        full_f_sentences[i] = line.split()\n",
    "\n",
    "dev_alignments = []\n",
    "for sentence in dev_a_sentences:\n",
    "    new_sentence = []\n",
    "    for word in sentence.split():\n",
    "        m = re.search('(\\d+)\\D(\\d+)', word)\n",
    "        new_sentence.append((m[1], m[2]))\n",
    "    dev_alignments.append(new_sentence)\n",
    "dev_a_sentences = dev_alignments\n",
    "# print(dev_a_sentences[0])\n",
    "# print(full_f_sentences[0])\n",
    "# print(full_e_sentences[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fast_sentences.txt\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for (f, e) in zip(full_f_sentences, full_e_sentences):\n",
    "        line = f\"{' '.join(f)} ||| {' '.join(e)}\\n\"\n",
    "        f_out.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dev_pair_count, dev_e_count = defaultdict(int), defaultdict(int) # Initialze all counts to 0\n",
    "for n, alignments in enumerate(dev_a_sentences): # Step through sentences\n",
    "    for alignment in alignments: # Step through observed alignment pairs\n",
    "        dev_pair_count[(dev_f_sentences[n][int(alignment[0])], dev_e_sentences[n][int(alignment[1])])] += 1 # Increment count of alignments between the two words\n",
    "        dev_e_count[dev_e_sentences[n][int(alignment[1])]] += 1 # Increment marginal count of English word\n",
    "p_fe = {word_pair: dev_pair_count[word_pair]/dev_e_count[word_pair[1]] for word_pair in dev_pair_count} # Normalize\n",
    "#print(p_fe)\n",
    "\n",
    "# \"\"\"\n",
    "# Honestly not sure at all how the Algo 1 pseudocode was supposed to use the observed alignments as given\n",
    "# in hansards.a, not only do the alignments look terrible at a glance, but the indexing is...weird.\n",
    "# \"\"\"\n",
    "# p_fe = defaultdict(float)\n",
    "# pair_count = defaultdict(int) # Initialze all counts to 0\n",
    "# e_count = defaultdict(int)\n",
    "# for n, a in enumerate(dev_a_sentences):\n",
    "#     for i, f in enumerate(dev_f_sentences[n], 1):\n",
    "#         for j, e in enumerate(dev_e_sentences[n], 1):          # Start from 0 to include null words\n",
    "#             if int(a[i][1]) == j:\n",
    "#                 pair_count[(f, e)] += 1  # Increment count of alignments between these two words\n",
    "#                 e_count[e] += 1            # Increment marginal count of English word\n",
    "# for word_pair in pair_count:\n",
    "#     p_fe[word_pair] = pair_count[word_pair]/e_count[word_pair[1]]            # Normalize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "k = 0\n",
    "theta = defaultdict(lambda:0.00000000000000000001) # A common choice is to initialize uniformly (didn't see any difference in starting values on dev set, will run multiple versions on full set...)\n",
    "while k < 8: # Until parameters converge or some other criterion, such as a fixed number of iterations is met\n",
    "    k += 1 \n",
    "    timer_start = timer()\n",
    "    full_pair_count, full_e_count = defaultdict(int), defaultdict(int) # Initialze all counts to 0\n",
    "    for n, F in enumerate(full_f_sentences): # E-Step: Compute expected counts\n",
    "        for f in F:\n",
    "            Z = 0 # Z is commonly used to denote a normalization term \n",
    "            for e in full_e_sentences[n]:\n",
    "                Z += theta[(f, e)]\n",
    "            for e in full_e_sentences[n]:\n",
    "                c = theta[(f, e)] / Z # Compute expected count\n",
    "                full_pair_count[(f, e)] += c # Increment count of alignments by expected count\n",
    "                full_e_count[e] += c # Increment marginal count of English word by expected count\n",
    "    theta = {word_pair: full_pair_count[word_pair]/full_e_count[word_pair[1]] for word_pair in full_pair_count} # M-Step:Normalize\n",
    "    #print(\"('très', 'very'):\", theta[('très', 'very')])\n",
    "    timer_stop = timer()\n",
    "    time = timer_stop - timer_start\n",
    "    #print(\"epoch\", k, \"took\", round(time), \"seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    theta_0 = (lambda:0.1), 10 epoch limit, sampling word pair ('très', 'very'). Total runtime: 12min 43sec\n",
    "    Results nearly identical to theta_0 = (lambda:1)\n",
    "    ('très', 'very'): 0.027585138264210947\n",
    "    epoch 1 took 77.6112612 seconds\n",
    "    ('très', 'very'): 0.225722140356126\n",
    "    epoch 2 took 82.6098117 seconds\n",
    "    ('très', 'very'): 0.4422172475438449\n",
    "    epoch 3 took 76.6076099 seconds\n",
    "    ('très', 'very'): 0.540104671629061\n",
    "    epoch 4 took 75.42177760000004 seconds\n",
    "    ('très', 'very'): 0.5835515176657871\n",
    "    epoch 5 took 77.22606769999993 seconds\n",
    "    ('très', 'very'): 0.6033351981591198\n",
    "    epoch 6 took 74.98604260000002 seconds\n",
    "    ('très', 'very'): 0.6119744755813445\n",
    "    epoch 7 took 72.43497400000001 seconds\n",
    "    ('très', 'very'): 0.6152246452183321\n",
    "    epoch 8 took 76.34132110000007 seconds\n",
    "    ('très', 'very'): 0.6159095087835013\n",
    "    epoch 9 took 72.46883460000004 seconds\n",
    "    ('très', 'very'): 0.6154325496303655\n",
    "    epoch 10 took 77.4239576 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    theta_0 = (lambda:1), 10 epoch limit, sampling word pair ('très', 'very'). Total runtime: 13min\n",
    "    8 epochs seems to be the end of rapid improvement, the guess even goes down marginally in epoch 10.\n",
    "    ('très', 'very'): 0.027585138264210947\n",
    "    epoch 1 took 73.8355653 seconds\n",
    "    ('très', 'very'): 0.225722140356126\n",
    "    epoch 2 took 84.44004360000001 seconds\n",
    "    ('très', 'very'): 0.44221724754384495\n",
    "    epoch 3 took 77.45663670000002 seconds\n",
    "    ('très', 'very'): 0.540104671629061\n",
    "    epoch 4 took 77.74768819999997 seconds\n",
    "    ('très', 'very'): 0.583551517665787\n",
    "    epoch 5 took 77.1224856 seconds\n",
    "    ('très', 'very'): 0.6033351981591198\n",
    "    epoch 6 took 80.14680129999999 seconds\n",
    "    ('très', 'very'): 0.6119744755813448\n",
    "    epoch 7 took 82.47481409999995 seconds\n",
    "    ('très', 'very'): 0.615224645218332\n",
    "    epoch 8 took 76.8060847999999 seconds\n",
    "    ('très', 'very'): 0.6159095087835013\n",
    "    epoch 9 took 74.31741080000006 seconds\n",
    "    ('très', 'very'): 0.6154325496303653\n",
    "    epoch 10 took 74.46382360000007 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    theta_0 = (lambda:0.00000000000000000001), 10 epoch limit, sampling word pair ('très', 'very').\n",
    "    stopped early after epoch 2, since results were identical to theta_0 = (lambda:0.1) and theta_0 = (lambda:1)\n",
    "    Am I missing something, that my lambda doesn't matter? Maybe it'll be obvious when I start looking for AER.\n",
    "    ('très', 'very'): 0.027585138264210954\n",
    "    epoch 1 took 76 seconds\n",
    "    ('très', 'very'): 0.225722140356126\n",
    "    epoch 2 took 78 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f987c9954b5baca0b38449ea0150956d6a4255bfbccda35dc613e620693466e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
